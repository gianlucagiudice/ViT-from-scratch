model_config:
  patch_size: 7
  latent_dim: 480
  n_layers: 14
  n_heads: 10
  dropout: 0.1
  input_shape: [1, 28, 28]
  n_classes: 10

training_config:
  learning_rate: 0.001
  max_epochs: 100
  early_stopping: 30
  seed: 42
  batch_size: 512
  wandb_logger: false
